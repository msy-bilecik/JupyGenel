{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wilcoxon Signed Rank Test\n",
    "*By P. Stikker*<br>\n",
    "https://PeterStatistics.com<br>\n",
    "https://www.youtube.com/stikpet<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test if scores on two paired ordinal variables are evenly distributed there are two tests often mentioned that can be used. Either a two-sample sign test, or a Wilcoxon signed rank test (Wilcoxon, 1945). In both tests the difference between the two variables for each case (respondent) is calculated first. The two-sample sign test then 'simply' checks if the number of positive differences is the same as the number of negative differences (or at least could be in the population). This test ignores the size of the difference, and this is something the Wilcoxon signed rank test does take into consideration to a certain extend. As the name implies it uses ranks to determine if the sum of the ranks is significantly different between the sum of the ranks of the positive differences and of the ranks of the negative differences. I'll use this test for the example.\n",
    "\n",
    "Note that the Wilcoxon test actually removes any ties, i.e. if the score on each variable is the same for a case, it will not be used. Pratt (1959) proposed an alternative method, that does still use these tied scores in the ranking, but it is a lot less known. Another approach might be an partially overlapping samples t-test (Derrick & White, 2018), but although this test might actually be the best to use, this would require to make some more assumptions about the data and is not well-known (yet)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show an example, I'll load some data as a pandas dataframe. So I'll need the '<a href=\"https://pandas.pydata.org\">pandas</a>' library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then load the example data using the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\">'read_csv'</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDf = pd.read_csv('wil.csv')\n",
    "myDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple method to perform a Wilcoxon test is to use the '<a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html\">wilcoxon</a>' function from the scipy.stats package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scipy\n",
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its important to remove any missing values from our data, so first create a new dataframe without any missing values. This can easily be done using Pandas '<a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html\">dropna</a>':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDf = myDf[['DC-diger', 'dc-biz']].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then perform the test simply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilcoxon(newDf['DC-diger'], newDf['dc-biz'], correction=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that there is less than .001 (0.1%) chance to get an absolute a statistic (W) of 85 or even more in a sample if there wouldn't be any difference in mean ranks in the population. \n",
    "\n",
    "This chance is so low that most likely there is a difference (usually below .05 is the threshold), which indicates that there is a significant difference between the two variables.\n",
    "\n",
    "The *correction=False* avoids that scipy uses a continuity correction. If you do want to use this, you can set it to true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilcoxon(newDf['DC-diger'], newDf['dc-biz'], correction=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scipy can also perform the 'Pratt' version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wilcoxon(newDf['DC-diger'], newDf['dc-biz'], zero_method='pratt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another parameter is the *mode*. By default this is set to *auto* which will use an exact Wilcoxon distribution if the number of pairs is 25 or less, and there are no ties, otherwise it will use the approximation with the normal distribution. We can also use mode='exact', but only if the number of pairs is 25 or less (so not in this example).\n",
    "\n",
    "There are some other packages that can also perform this test, but most of them have less options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the '<a href=\"https://researchpy.readthedocs.io/en/latest/ttest_documentation.html\">ttest</a>' function from researchpy to perform the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyNonpar\n",
    "from researchpy import ttest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpRes = ttest(newDf['DC-diger'], newDf['dc-biz'], equal_variances=False, paired=True)\n",
    "rpRes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The z-value reported here is not adjusted for ties. Its based on the formula:\n",
    "\n",
    "\\begin{equation*}\n",
    "Z = \\frac{W - \\mu}{\\sqrt{\\sigma^2}}\n",
    "\\end{equation*}\n",
    "\n",
    "In this formula $W$ is the W-statistic (the T in the output above). For $\\mu$ the following formula is used:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mu = \\frac{n_r\\times\\left(n_r+1\\right)}{4}\n",
    "\\end{equation*}\n",
    "\n",
    "Where $n_r$ is the number of ranks (which is the number of pairs that are not equal), and is $\\sigma^2$ defined as:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\sigma^2 = \\frac{n_r\\times\\left(n_r+1\\right)\\times\\left(2\\times n_r+1\\right)}{6}\n",
    "\\end{equation*}\n",
    "\n",
    "We can also use the '<a href=\"https://pingouin-stats.org/generated/pingouin.wilcoxon.html\">wilcoxon</a>' function from pingouin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pingouin import wilcoxon as pgWilc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgWilc(newDf['DC-diger'], newDf['dc-biz'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pingouin always applies the correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those interested, in the appendix I'll go over the formulas involved and avoid using libraries as much as possible (only for the normal distribution to get the eventuel p-value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Derrick, B., & White, P. (2018). Methods for comparing the responses from a Likert question, with paired observations and independent observations in each of two samples. *International Journal of Mathematics and Statistics, 19*(3), 84–93.\n",
    "\n",
    "Pratt, J. W. (1959). Remarks on Zeros and Ties in the Wilcoxon Signed Rank Procedures. *Journal of the American Statistical Association, 54*(287), 655–667. doi:10.1080/01621459.1959.10501526\n",
    "\n",
    "Wilcoxon, F. (1945). Individual comparisons by ranking methods. *Biometrics Bulletin, 1*(6), 80. doi:10.2307/3001968\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: The Hard Way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we convert our pandas series to a Python native format: a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = list(newDf['DC-diger'])\n",
    "list2 = list(newDf['dc-biz'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to create a list of tuples, excluding any situation where the two values are equal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(list1)):\n",
    "    if list1[i]!=list2[i]:\n",
    "        X = X + [(list1[i], list2[i])]\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Python native's len function to determine the number of pairs we now have (nr):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr = len(X)\n",
    "nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each tuple determine the absolute difference, and also keep track of which one was larger.\n",
    "\n",
    "In formula notation:\n",
    "\n",
    "\\begin{equation*}\n",
    "D_i = |X_{i_x} - X_{i_y}|\n",
    "\\end{equation*}\n",
    "\n",
    "In this formula $X_{i_x}$ is the x-value of the i-the pair, and $X_{i_y}$ the y value.\n",
    "\n",
    "For the sign we can use:\n",
    "\\begin{equation*}\n",
    "sign = \\left\\{\\begin{matrix}\n",
    "-1 & \\text{if } X_{i_x}<X_{i_y}\\\\ \n",
    "1 & \\text{if } X_{i_x}>X_{i_y} \n",
    "\\end{matrix}\\right.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = []\n",
    "sg = []\n",
    "for i in range(nr):\n",
    "    D = D + [abs(X[i][0]-X[i][1])]\n",
    "    if X[i][0]>X[i][1]:\n",
    "        sg = sg + [1]\n",
    "    else:\n",
    "        sg = sg + [-1]\n",
    "    \n",
    "print(D)\n",
    "print(sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to rank these differences. I'll re-use my rank function made for the Spearman rho (see separate documentation for some more details). The adjustment made here, is that it will also return a dictionary with the frequency of each unique rank, which will come in handy later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rankList2(aList):\n",
    "    sortList = aList.copy()\n",
    "    sortList.sort()\n",
    "    \n",
    "    latestRank = 1\n",
    "    rankDict = {}\n",
    "    rankFreq = {}\n",
    "    freqScore = 1\n",
    "    for i in range(1, len(sortList)):\n",
    "\n",
    "        if sortList[i] == sortList[i-1]:\n",
    "            freqScore = freqScore + 1\n",
    "\n",
    "        if sortList[i] != sortList[i-1]:\n",
    "            rank = (2*latestRank + freqScore - 1) / 2\n",
    "\n",
    "            rankDict[sortList[i-1]] = rank\n",
    "            rankFreq[rank] = freqScore\n",
    "            latestRank = latestRank + freqScore\n",
    "            freqScore = 1\n",
    "\n",
    "    # the last case\n",
    "    rankDict[sortList[len(sortList)-1]] = (2*latestRank + freqScore - 1) / 2\n",
    "    rankFreq[(2*latestRank + freqScore - 1) / 2] = freqScore\n",
    "    \n",
    "    # replace list scores with rank scores\n",
    "    allRanks = []\n",
    "    for i in aList:\n",
    "        allRanks.append(rankDict[i])\n",
    "    \n",
    "    return rankFreq, allRanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rFreq, R = rankList2(D)\n",
    "print(R)\n",
    "print(rFreq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now determine two W-values. One for all the positive ranks, and one for all the negative:\n",
    "\n",
    "\\begin{equation*}\n",
    "W_+ = \\sum_{i \\text{ if } sign(i)>0}R_i\n",
    "\\end{equation*}\n",
    "\n",
    "and\n",
    "\n",
    "\\begin{equation*}\n",
    "W_- = \\sum_{i \\text{ if } sign(i)<0}R_i\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wplus = 0\n",
    "Wmin = 0\n",
    "\n",
    "for i in range(nr):\n",
    "    if sg[i]>0:\n",
    "        Wplus = Wplus + R[i]\n",
    "    else:\n",
    "        Wmin = Wmin + R[i]\n",
    "        \n",
    "Wplus, Wmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mu = \\frac{n_r\\times\\left(n_r+1\\right)}{4}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nr * (nr + 1) / 4\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\sigma^2 = \\frac{n_r\\times\\left(n_r+1\\right)\\times\\left(2\\times n_r+1\\right)}{24}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = nr * (nr + 1) * (2*nr + 1) / 24\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine the correction for ties, we calculate first:\n",
    "\n",
    "\\begin{equation*}\n",
    "T = \\sum \\left( t_{i}^3 - t_i \\right)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 0\n",
    "for key in rFreq:\n",
    "    T = T + rFreq[key]**3 - rFreq[key]\n",
    "    \n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjusted variance is then given by:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\sigma_{adj}^2 = \\sigma^2 - \\frac{T}{48}\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varAdj = var - T/48\n",
    "varAdj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard error can then be defined as:\n",
    "\n",
    "\\begin{equation*}\n",
    "SE_{adj} = \\sqrt{\\sigma_{adj}^2}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEadj = varAdj**0.5\n",
    "SEadj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally the z-value as:\n",
    "\n",
    "\\begin{equation*}\n",
    "Z = \\frac{W_+}{SE_{adj}}\n",
    "\\end{equation*}\n",
    "\n",
    "or\n",
    "\\begin{equation*}\n",
    "Z = \\frac{W_-}{SE_{adj}}\n",
    "\\end{equation*}\n",
    "\n",
    "The difference between these two will only be in a negative sign in front of one, and not the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = (Wplus - m) / SEadj\n",
    "Z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2 = (Wmin - m) / SEadj\n",
    "Z2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use scipy.stats now to convert these z-values to a p-value using the standard normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*(1-norm.cdf(abs(Z2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2*(1-norm.cdf(abs(Z2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
