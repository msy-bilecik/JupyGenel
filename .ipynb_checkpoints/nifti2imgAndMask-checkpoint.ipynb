{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nifti image read, convert to png "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nifti for convert tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import skimage, os\n",
    "from skimage.morphology import ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, binary_opening\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage import measure, feature\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import data,color\n",
    "from scipy import ndimage as ndi\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from skimage.io import imread\n",
    "import nibabel as nib\n",
    "import imageio\n",
    "import cv2\n",
    "from PIL import Image, ImageCms\n",
    "from skimage.util import img_as_ubyte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "import cv2\n",
    "import skimage, os\n",
    "\n",
    "def calArea(xs,ys):\n",
    "    minX=min(xs)\n",
    "    maxX=max(xs)\n",
    "    minY=min(ys)\n",
    "    maxY=max(ys)\n",
    "    area=(maxY-minY)*(maxX-minX)\n",
    "    #print(xs)\n",
    "    #print(ys)\n",
    "    #print(\"{} {} {} {} {} {} ALANI :{}\".format(maxY,minY,maxX,minX,maxY-minY,maxX-minX,area))\n",
    "    return area\n",
    "\n",
    "def choiseLession(cnt,thX):\n",
    "    cntX=[]\n",
    "    for item in cnt:\n",
    "        xs=[]\n",
    "        ys=[]\n",
    "        \n",
    "        #cn=0\n",
    "        for ix in item:\n",
    "            xs.append(ix[0][0])\n",
    "            ys.append(ix[0][1])        \n",
    "            area=calArea(xs,ys)\n",
    "        \n",
    "        if(area>=thX):\n",
    "            cntX.append([xs,ys])\n",
    "            \n",
    "    return cntX\n",
    "\n",
    "\n",
    "\n",
    "def img2jsonAnn(sourcePath,imgPatch,maskSource,maskPatch):\n",
    "    all_images =sorted(glob(os.path.join(sourcePath,'*'+imgPatch+'*')))\n",
    "    all_masks  =sorted(glob(os.path.join(maskSource,'*'+maskPatch+'*')))\n",
    "    print(len(all_masks))\n",
    "    data = {}\n",
    "    i=0\n",
    "    for i in range(len(all_images)):\n",
    "        print(\"{}) {} - {}\".format(i,all_images[i],all_masks[i]))\n",
    "    i=0\n",
    "    for item in all_masks:\n",
    "        \n",
    "        img=all_images[i]\n",
    "        sizeX=os.stat(img).st_size\n",
    "        fname=os.path.basename(img)\n",
    "        fnameA=fname.split(\"_\")\n",
    "        key=str(fname)+\"\"+str(sizeX)\n",
    "        \n",
    "        value={}\n",
    "        value[\"fileref\"]=\"\"\n",
    "        value[\"size\"]=sizeX\n",
    "        value[\"filename\"]=fname\n",
    "        value[\"base64_img_data\"]=\"\"\n",
    "        fileattributes={}\n",
    "        value[\"fileattributes\"]=fileattributes\n",
    "\n",
    "        regions={}\n",
    "        shape_attributes={}\n",
    "        region_attributes={}\n",
    "        region_attributes[\"label\"]=\"msMask\"\n",
    "        \n",
    "        src = cv2.imread(item)\n",
    "        gray = cv2.cvtColor(src,cv2.COLOR_BGR2GRAY)\n",
    "        blur = cv2.blur(gray, (2, 2))\n",
    "        ret, thresh = cv2.threshold(blur, 100, 255, cv2.THRESH_TOZERO)\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        \n",
    "        cnt = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "                # ROI will be object with biggest contour\n",
    "        #mask = contours[0]\n",
    "        #print(len(cnt))\n",
    "        cntX=choiseLession(cnt,0)\n",
    "        #print(len(cntX))\n",
    "        c1=0\n",
    "        for item in cntX:\n",
    "            xs=item[0]\n",
    "            xs.append(xs[0])\n",
    "            ys=item[1]\n",
    "            ys.append(ys[0])\n",
    "            all_points_x=xs\n",
    "            all_points_y=ys\n",
    "            dd={}\n",
    "            shape_attributes={}\n",
    "            shape_attributes[\"name\"]=\"polygon\"\n",
    "            xs.append(xs[0])\n",
    "            ys.append(ys[0])\n",
    "            shape_attributes[\"all_points_x\"]=str(xs)\n",
    "            shape_attributes[\"all_points_y\"]=str(ys)\n",
    "            dd[\"shape_attributes\"]=shape_attributes\n",
    "            dd[\"region_attributes\"]=region_attributes\n",
    "            regions[str(c1)]=dd\n",
    "            c1=c1+1\n",
    "        value[\"regions\"]=regions\n",
    "        data[key]=value    \n",
    "        i=i+1\n",
    "    json_data = json.dumps(data)\n",
    "\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcePath =\"D:\\\\datasets\\\\lung\\\\vessel12\\\\vessel12_secim500\\\\train\"\n",
    "imgPatch   =\"slice\"\n",
    "maskSource =\"D:\\\\datasets\\\\lung\\\\vessel12\\\\vessel12_secim500\\\\trainMask\"\n",
    "maskPatch  =\"mask\"\n",
    "s=img2jsonAnn(sourcePath,imgPatch,maskSource,maskPatch)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "filepath=\"D:\\\\FW_ilkhasta\\\\\"\n",
    "BASE_IMG_PATH=os.path.join('..',filepath)\n",
    "Target_IMG_PATH=\"D:\\\\FW_ilkhasta\\\\\"\n",
    "print(BASE_IMG_PATH)\n",
    "\n",
    "all_images=sorted(glob(os.path.join(BASE_IMG_PATH,'*Flair*')))\n",
    "all_masks =sorted(glob(os.path.join(BASE_IMG_PATH,'*msplak*')))\n",
    "i=0\n",
    "for item in all_images:\n",
    "    fname=os.path.basename(all_images[i])\n",
    "    fnameA=fname.split(\"_\")\n",
    "    test_image=nib.load(all_images[i]).get_fdata()\n",
    "    test_mask=nib.load(all_masks[i]).get_fdata()\n",
    "    i=i+1\n",
    "\n",
    "    r=test_image.shape[2]\n",
    "    for yy in range(0,r):\n",
    "        #print(yy)\n",
    "        img=test_image[:,:,yy]\n",
    "        img=np.rot90(img)\n",
    "        img = img.astype(np.uint8)\n",
    "        imageName='{}{}_slices_{:03}.png'.format(Target_IMG_PATH,fnameA[0], yy)\n",
    "        imageio.imwrite(imageName, img)\n",
    "        print(imageName,\" saved\")\n",
    "        maskImg=test_mask[:,:,yy]\n",
    "        maskImg=np.rot90(maskImg)*255\n",
    "        maskImg = maskImg.astype(np.uint8)\n",
    "        mimageName='{}{}_slices_{:03}.png'.format(Target_IMG_PATH,fnameA[0], yy)\n",
    "        imageio.imwrite(mimageName, maskImg)\n",
    "        print(mimageName,\" saved\")\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath=\"D:\\\\datasets\\\\ms\\\\miccai2008\\\\flair\\\\\"\n",
    "BASE_IMG_PATH=os.path.join('..',filepath)\n",
    "Target_IMG_PATH=\"D:\\\\datasets\\\\ms\\\\miccai2008\\\\flairPNG\\\\\"\n",
    "print(BASE_IMG_PATH)\n",
    "print(Target_IMG_PATH)\n",
    "\n",
    "all_images=sorted(glob(os.path.join(BASE_IMG_PATH,'*.nii')))\n",
    "i=0\n",
    "for item in all_images:\n",
    "    fname=os.path.basename(all_images[i])\n",
    "    fnameA=fname.split(\".\")[0]\n",
    "    print(fnameA)\n",
    "    test_image=nib.load(all_images[i]).get_fdata()\n",
    "    i=i+1\n",
    "    r=test_image.shape[2]\n",
    "    t_img_path=os.path.join(Target_IMG_PATH, fnameA)\n",
    "    fnameA1=fnameA.split(\"_\")\n",
    "    parentName=\"parent_\"+fnameA1[0]+\"_\"+fnameA1[2]\n",
    "    if not os.path.exists(t_img_path):\n",
    "        os.makedirs(t_img_path)\n",
    "    for yy in range(0,r):\n",
    "        #print(yy)\n",
    "        img=test_image[:,:,yy]\n",
    "        if(sum(img)>10):\n",
    "            img=np.rot90(img)\n",
    "            img.astype(np.uint8)\n",
    "            imageName='{}\\\\{}_slices_{:04}.jpg'.format(t_img_path, parentName, yy)\n",
    "            imageio.imwrite(imageName, img)\n",
    "            print(imageName,\" saved\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maskelere göre dolu olan slicelerı kaydeden bir yapı ayrı ayrı klasörlere kaydeden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath=\"D:\\\\datasets\\\\ms\\\\isbi\\\\flair\\\\\"\n",
    "maskpath=\"D:\\\\datasets\\\\ms\\\\isbi\\\\mask\\\\\"\n",
    "BASE_IMG_PATH=os.path.join('..',filepath)\n",
    "Target_IMG_PATH = \"D:\\\\datasets\\\\ms\\\\isbi\\\\flairPNG2\\\\\"\n",
    "print(BASE_IMG_PATH)\n",
    "print(Target_IMG_PATH)\n",
    "\n",
    "all_images=sorted(glob(os.path.join(BASE_IMG_PATH,'*.nii')))\n",
    "all_mask_i=sorted(glob(os.path.join(maskpath,'*.nii')))\n",
    "for item in all_mask_i:\n",
    "\n",
    "    fname=os.path.basename(item)\n",
    "    fnameA=fname.split(\".\")[0]\n",
    "    print(fnameA)\n",
    "    test_image=nib.load(item).get_fdata()\n",
    "    r=test_image.shape[2]\n",
    "    fnameA1=fnameA.split(\"_\")\n",
    "    display(fname)\n",
    "    display(fnameA1)\n",
    "    parentName=\"parent_\"+fnameA1[0]+\"_\"+fnameA1[1]\n",
    "    \n",
    "    \n",
    "    imgName=fname.replace(\"maskl\",\"flair_pp\")\n",
    "    imgPath=os.path.join(filepath,imgName)\n",
    "    imgMR=nib.load(imgPath).get_fdata()\n",
    "    print(os.path.exists(os.path.join(filepath,imgName)))\n",
    "    \n",
    "    t_img_path=os.path.join(Target_IMG_PATH, fnameA)\n",
    "    t_mask_path=os.path.join(t_img_path, \"GTMask\")\n",
    "    \n",
    "    if not os.path.exists(t_img_path):\n",
    "        os.makedirs(t_img_path)\n",
    "    if not os.path.exists(t_mask_path):\n",
    "        os.makedirs(t_mask_path)  \n",
    "\n",
    "    for yy in range(0,r):\n",
    "        #print(yy)\n",
    "        img=test_image[:,:,yy]\n",
    "        imgx=img\n",
    "        if(imgx.sum()>10):\n",
    "            img=np.rot90(img)\n",
    "            img.astype(np.uint8)\n",
    "            imageName='{}\\\\{}_GTmask_{:04}.jpg'.format(t_mask_path, parentName, yy)\n",
    "            imageio.imwrite(imageName, img)\n",
    "            print(imageName,\" saved\")\n",
    "            \n",
    "            img=imgMR[:,:,yy]\n",
    "            img=np.rot90(img)\n",
    "            img.astype(np.uint8)\n",
    "            imageName='{}\\\\{}_slice_{:04}.jpg'.format(t_img_path, parentName, yy)\n",
    "            imageio.imwrite(imageName, img)\n",
    "            print(imageName,\" saved\")\n",
    "            \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## maskelere göre dolu olan slicelerı kaydeden bir yapı tek klasörlere kaydeden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath=\"D:\\\\datasets\\\\ms\\\\isbi\\\\flair\\\\\"\n",
    "maskpath=\"D:\\\\datasets\\\\ms\\\\isbi\\\\mask\\\\\"\n",
    "Target_IMG_PATH = \"D:\\\\datasets\\\\ms\\\\isbi\\\\flairPNG2\\\\\"\n",
    "Target_MASK_PATH = \"D:\\\\datasets\\\\ms\\\\isbi\\\\maskPNG2\\\\\"\n",
    "maskPatch=\"mask1\"\n",
    "imgPatch=\"flair_pp\"\n",
    "print(BASE_IMG_PATH)\n",
    "print(Target_IMG_PATH)\n",
    "\n",
    "t_img_path=Target_IMG_PATH\n",
    "t_mask_path=Target_MASK_PATH\n",
    "\n",
    "all_images=sorted(glob(os.path.join(BASE_IMG_PATH,'*.nii')))\n",
    "all_mask_i=sorted(glob(os.path.join(maskpath,'*.nii')))\n",
    "for item in all_mask_i:\n",
    "\n",
    "    fname=os.path.basename(item)\n",
    "    fnameA=fname.split(\".\")[0]\n",
    "    print(fnameA)\n",
    "    test_image=nib.load(item).get_fdata()\n",
    "    r=test_image.shape[2]\n",
    "    fnameA1=fnameA.split(\"_\")\n",
    "    parentName=\"parent_\"+fnameA1[0]+\"_\"+fnameA1[1]\n",
    "    \n",
    "    \n",
    "    imgName=fname.replace(maskPatch,imgPatch)\n",
    "    imgPath=os.path.join(filepath,imgName)\n",
    "    imgMR=nib.load(imgPath).get_fdata()\n",
    "    print(os.path.exists(os.path.join(filepath,imgName)))\n",
    "    \n",
    "#     t_img_path=os.path.join(Target_IMG_PATH, fnameA)\n",
    "#     t_mask_path=os.path.join(t_img_path, \"GTMask\")\n",
    "    \n",
    "#     if not os.path.exists(t_img_path):\n",
    "#         os.makedirs(t_img_path)\n",
    "#     if not os.path.exists(t_mask_path):\n",
    "#         os.makedirs(t_mask_path)  \n",
    "\n",
    "    for yy in range(0,r):\n",
    "        #print(yy)\n",
    "        img=test_image[:,:,yy]\n",
    "        imgx=img\n",
    "        if(imgx.sum()>10):\n",
    "            img=np.rot90(img)\n",
    "            img.astype(np.uint8)\n",
    "            imageName='{}\\\\{}_GTmask_{:04}.jpg'.format(t_mask_path, parentName, yy)\n",
    "            imageio.imwrite(imageName, img)\n",
    "            print(imageName,\" saved\")\n",
    "            \n",
    "            img=imgMR[:,:,yy]\n",
    "            img=np.rot90(img)\n",
    "            img.astype(np.uint8)\n",
    "            imageName='{}\\\\{}_slice_{:04}.jpg'.format(t_img_path, parentName, yy)\n",
    "            imageio.imwrite(imageName, img)\n",
    "            print(imageName,\" saved\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def calArea(xs,ys):\n",
    "    minX=min(xs)\n",
    "    maxX=max(xs)\n",
    "    minY=min(ys)\n",
    "    maxY=max(ys)\n",
    "    area=(maxY-minY)*(maxX-minX)\n",
    "    #print(xs)\n",
    "    #print(ys)\n",
    "    #print(\"{} {} {} {} {} {} ALANI :{}\".format(maxY,minY,maxX,minX,maxY-minY,maxX-minX,area))\n",
    "    return area\n",
    "\n",
    "def choiseLession(cnt,thX):\n",
    "    cntX=[]\n",
    "    for item in cnt:\n",
    "        xs=[]\n",
    "        ys=[]\n",
    "        \n",
    "        #cn=0\n",
    "        for ix in item:\n",
    "            xs.append(ix[0][0])\n",
    "            ys.append(ix[0][1])        \n",
    "            area=calArea(xs,ys)\n",
    "        \n",
    "        if(area>=thX):\n",
    "            cntX.append([xs,ys])\n",
    "            \n",
    "    return cntX\n",
    "        \n",
    "data = {}\n",
    "sizeX=os.stat('D:\\\\datasets\\\\3dwmlmr2\\\\patient01_slices_106_flair.png').st_size\n",
    "fname=os.path.basename('D:\\\\datasets\\\\3dwmlmr2\\\\patient01_slices_106_flair.png')\n",
    "fnameA=fname.split(\"_\")\n",
    "key=str(fname)+\"\"+str(sizeX)\n",
    "value={}\n",
    "value[\"fileref\"]=\"\"\n",
    "value[\"size\"]=sizeX\n",
    "value[\"filename\"]=fname\n",
    "value[\"base64_img_data\"]=\"\"\n",
    "fileattributes={}\n",
    "value[\"fileattributes\"]=fileattributes\n",
    "\n",
    "regions={}\n",
    "shape_attributes={}\n",
    "region_attributes={}\n",
    "region_attributes[\"label\"]=\"msMask\"\n",
    "\n",
    "src = cv2.imread(\"D:\\\\datasets\\\\3dwmlmr2\\\\patient01_slices_106_GTmask.png\")\n",
    "\n",
    "#print(src)\n",
    "gray = cv2.cvtColor(src,cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.blur(gray, (3, 3))\n",
    "# binary thresholding of the image\n",
    "ret, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY)\n",
    "        # ret, thresh = cv2.threshold(gray, 127, 255,0)\n",
    "\n",
    "        # find contours\n",
    "        # contours, hierarchy = cv2.findContours(thresh,2,1)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        # cc\n",
    "cnt = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        # ROI will be object with biggest contour\n",
    "mask = contours[0]\n",
    "print(len(cnt))\n",
    "\n",
    "cntX=choiseLession(cnt,50)\n",
    "print(len(cntX))\n",
    "c1=0\n",
    "for item in cntX:\n",
    "    xs=item[0]\n",
    "    xs.append(xs[0])\n",
    "    ys=item[1]\n",
    "    ys.append(ys[0])\n",
    "    all_points_x=xs\n",
    "    all_points_y=ys\n",
    "    dd={}\n",
    "    shape_attributes={}\n",
    "    shape_attributes[\"name\"]=\"polygon\"\n",
    "    xs.append(xs[0])\n",
    "    ys.append(ys[0])\n",
    "    shape_attributes[\"all_points_x\"]=str(xs)\n",
    "    shape_attributes[\"all_points_y\"]=str(ys)\n",
    "    dd[\"shape_attributes\"]=shape_attributes\n",
    "    dd[\"region_attributes\"]=region_attributes\n",
    "    regions[str(c1)]=dd\n",
    "    c1=c1+1\n",
    "    \n",
    "value[\"regions\"]=regions\n",
    "\n",
    "data[key]=value    \n",
    "json_data = json.dumps(data)\n",
    "print(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter notebook --NotbookApp.iopub_Data_Rate_Limit=1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('hh.png')\n",
    "res = cv2.resize(img, dsize=(192, 256), interpolation=cv2.INTER_LANCZOS4)\n",
    "plt.imshow(res)\n",
    "imageio.imwrite(\"hh2.png\", res)\n",
    "\n",
    "img = cv2.imread('maskhh.png')\n",
    "res = cv2.resize(img, dsize=(192, 256), interpolation=cv2.INTER_LANCZOS4)\n",
    "plt.imshow(res)\n",
    "imageio.imwrite(\"maskhh2.png\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage, os\n",
    "from glob import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "filepath=\"D:\\\\\"\n",
    "BASE_IMG_PATH=os.path.join('..',filepath)\n",
    "Target_IMG_PATH=\"d:\\\\test\\\\\"\n",
    "print(BASE_IMG_PATH)\n",
    "\n",
    "all_images=sorted(glob(os.path.join(BASE_IMG_PATH,'*.nii*')))\n",
    "i=0\n",
    "for item in all_images:\n",
    "    fname=os.path.basename(all_images[i])\n",
    "    print(fname)\n",
    "    fnameA=fname.split(\".\")\n",
    "    test_image=nib.load(all_images[i]).get_fdata()\n",
    "    i=i+1\n",
    "\n",
    "    r=test_image.shape[2]\n",
    "    print(r)\n",
    "    for yy in range(0,r):\n",
    "        print(yy)\n",
    "        img=test_image[:,:,yy]\n",
    "        img=np.flip(img,axis=0)\n",
    "        img=np.rot90(img,1)\n",
    "        if(yy==13):\n",
    "            plt.imshow(img)\n",
    "#             display(img)\n",
    "            display(np.histogram(img))\n",
    "#         img = img.astype(np.uint8)\n",
    "        imageName='{}{}_slices_{:03}.jpg'.format(Target_IMG_PATH,fnameA[0], yy)\n",
    "        imageio.imwrite(imageName, img)\n",
    "        print(imageName,\" saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dicom2nifti\n",
    "import dicom2nifti.settings as settings\n",
    "\n",
    "\n",
    "original_dicom_directory=\"D:\\\\datasets\\\\lung\\\\ild\\\\ILD_DB_lungMasksK\\\\101\\\\orj\\\\\"\n",
    "output_file=\"D:\\\\sdds.nii.gz\"\n",
    "dicom2nifti.dicom_series_to_nifti(original_dicom_directory, output_file, reorient_nifti=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganization file system \n",
    "# ild files seperate each folder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "def fast_scandir(dirname):\n",
    "    subfolders    = [f.path for f in os.scandir(dirname) if f.is_dir()]\n",
    "    \n",
    "    for dirname in list(subfolders):\n",
    "        subfolders.extend(fast_scandir(dirname))\n",
    "#     sorted(subfolders) #.sort(key=lambda f: int(filter(str.isdigit, f)))\n",
    "    return subfolders\n",
    "\n",
    "def folder2fname(dirname):\n",
    "    dnX=dirname.split('\\\\')\n",
    "    nameX=\"parent\"+dnX[0]\n",
    "    for d in range(1,len(dnX)):\n",
    "        nameX+=\"_\"+dnX[d]\n",
    "    return nameX\n",
    "\n",
    "root_dir = 'D:\\\\datasets\\\\lung\\\\ild\\\\ILD_DB_lungMasksK\\\\'\n",
    "target_root_dir = 'D:\\\\datasets\\\\lung\\\\ild\\\\ILD_DB_lungMasksK\\\\images\\\\'\n",
    "\n",
    "fList=fast_scandir(root_dir)\n",
    "# display(fList)\n",
    "fListName=[]\n",
    "for dirname in fList:\n",
    "    dn=dirname.replace(root_dir, \"\")\n",
    "    dnX=folder2fname(dn)\n",
    "    fListName.append(dnX) \n",
    "display(fListName)\n",
    "\n",
    "    \n",
    "# file_names = os.listdir(source_dir)\n",
    "    \n",
    "# for file_name in file_names:\n",
    "#     shutil.move(os.path.join(source_dir, file_name), target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "inputdir = \"D:\\\\datasets\\\\lung\\\\ild\\\\ILD_DB_lungMasksK\\\\101\\\\CT-0002-0001.dcm\"\n",
    "outdir = \"D:\\\\datasets\\\\lung\\\\ild\\\\ILD_DB_lungMasksK\\\\101\\\\\"\n",
    "\n",
    "ds = pydicom.dcmread(inputdir)\n",
    "img = ds.pixel_array\n",
    "display(np.histogram(img))\n",
    "threshold = 500 # Adjust as needed\n",
    "img_s = np.array((np.maximum(img, 0) / (np.amax(img) + threshold)) * 255.0, dtype=int)\n",
    "display(np.histogram(img_s))\n",
    "cv2.imwrite(outdir +\"ff.png\" ,img_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "dicomDic=\"D:\\\\datasets\\\\lung\\\\ild\\\\ILD_DB_volumeROIs\\\\7\\\\\"\n",
    "# load the DICOM files\n",
    "files = []\n",
    "print('glob: {}'.format(dicomDic))\n",
    "for fname in glob.glob(dicomDic, recursive=False):\n",
    "    print(\"loading: {}\".format(fname))\n",
    "    files.append(pydicom.dcmread(fname))\n",
    "\n",
    "print(\"file count: {}\".format(len(files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dicom_parser import Image\n",
    "dicomF=\"D:\\\\datasets\\\\lung\\\\ild\\\\ILD_DB_volumeROIs\\\\7\\\\CT-7771-0001.dcm\"\n",
    "image = Image(dicomF)\n",
    "\n",
    "raw_value = image.header.raw['ImagingFrequency'].value\n",
    "raw_value\n",
    "type(raw_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
