{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "my format of json\n",
    "\n",
    "{\n",
    "\"image1.jpg\":{\n",
    "        \"filename\":\"image1.jpg\",\n",
    "        \"size\":123456,\n",
    "        \"regions\":[\n",
    "            {\n",
    "                \"shape_attributes\":{\n",
    "                    \"all_points_x\":[\n",
    "                        675,\n",
    "                        808,\n",
    "                        957,\n",
    "                        967,\n",
    "                        929,\n",
    "                        791,\n",
    "                        678,\n",
    "                        703\n",
    "                    ],\n",
    "                    \"all_points_y\":[\n",
    "                        543,\n",
    "                        518,\n",
    "                        492,\n",
    "                        722,\n",
    "                        760,\n",
    "                        760,\n",
    "                        760,\n",
    "                        647\n",
    "                    ],\n",
    "                    \"name\":\"polygon\"\n",
    "                },\n",
    "                \"region_attributes\":{\n",
    "                    \"Object\":\"class1\",\n",
    "                }\n",
    "            },...all other regions..{}]\n",
    "    }, ..all other images..., {}\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import glob, os, cv2\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from PIL import Image\n",
    "from scipy.spatial import Delaunay as Delaunay2D\n",
    "import json\n",
    "\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculateDelauneyPoints(points):\n",
    "    points= np.array(points).astype(int)\n",
    "    points= [list(item) for item in points]\n",
    "    dt = Delaunay2D()\n",
    "    for s in points:\n",
    "        dt.addPoint(s)\n",
    "    coord, tris= dt.exportDT()\n",
    "    return np.array(coord)\n",
    "\n",
    "def maskImage(filename, polygons, o_list):\n",
    "    root_path= '/3dircab/'\n",
    "    image = cv.imread(root_path+\"train/\"+filename)\n",
    "    mask = np.zeros(shape = image.shape, dtype = \"uint8\")\n",
    "    i= 0\n",
    "    for points in polygons:\n",
    "        points= [(int(x), int(y)) for x,y in points]\n",
    "        try:\n",
    "            rect= calculateDelauneyPoints(points)\n",
    "        except:\n",
    "            continue\n",
    "        if o_list[i] in ['class1']:\n",
    "            cv.drawContours(mask,[rect], -1,(1, 1, 1),cv.FILLED)\n",
    "        elif o_list[i] in ['class2']:\n",
    "            cv.drawContours(mask,[rect], -1,(2, 2, 2),cv.FILLED)\n",
    "        elif o_list[i] in ['class3']:\n",
    "            cv.drawContours(mask,[rect], -1,(3, 3, 3),cv.FILLED)\n",
    "        i+= 1\n",
    "    \n",
    "    cv.imwrite(root_path+\"dataset/images/\"+os.path.splitext(filename)[0]+\".png\", image)\n",
    "    cv.imwrite(root_path+\"dataset/masks/\"+os.path.splitext(filename)[0]+\".png\", mask)\n",
    "    \n",
    "    print(filename+\"ok\")   \n",
    "def getRegionProperties(region):\n",
    "    shape_attributes= region[\"shape_attributes\"]\n",
    "    region_attributes= region[\"region_attributes\"]\n",
    "    objects= region_attributes[\"Object\"]\n",
    "    regions= ['msMask']\n",
    "    all_points_x= shape_attributes[\"all_points_x\"]\n",
    "    all_points_y= shape_attributes[\"all_points_y\"]\n",
    "    coordinates= []\n",
    "    for i in range(0, len(all_points_x)):\n",
    "        coordinates.append((all_points_x[i], all_points_y[i]))\n",
    "    \n",
    "    return (objects, coordinates)\n",
    "\n",
    "def parallelizePlotting(data, region_mappings, json_data):\n",
    "    \n",
    "    polygon_coordinates= {}\n",
    "    polygons= []\n",
    "    img_json_data= json_data[data]\n",
    "    \n",
    "    filename= img_json_data[\"filename\"]\n",
    "    \n",
    "    # Open the original image here\n",
    "    image_matrix= np.array(Image.open('../data/all_images/'+filename), dtype= np.uint8)\n",
    "    region_data= img_json_data[\"regions\"]\n",
    "    objects_list= []\n",
    "    \n",
    "    for region in region_data:\n",
    "        objects, coordinates= getRegionProperties(region)\n",
    "        if coordinates is not None:\n",
    "            polygons.append(coordinates)\n",
    "            polygon_coordinates[objects]= coordinates\n",
    "            objects_list.append(objects)\n",
    "    \n",
    "    # Masking the images\n",
    "    maskImage(filename, polygons, objects_list)\n",
    "    return (filename, polygon_coordinates)\n",
    "\n",
    "\n",
    "import json\n",
    "def main():\n",
    "    \n",
    "    root_path= \"C:/workplace/data/\"\n",
    "\n",
    "    json_file= open(root_path+'via_region_data.json')\n",
    "    json_data= json.load(json_file)\n",
    "    \n",
    "    # for multiprocessing\n",
    "    pool = mp.Pool(mp.cpu_count()-1)\n",
    "    \n",
    "    def resultCallback(item):\n",
    "        return\n",
    "        \n",
    "    for data in json_data:\n",
    "        pool.apply_async(parallelizePlotting, args=(data, json_data), callback= resultCallback)\n",
    "    \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage import draw\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "###################  INSTALLATION NOTE #######################\n",
    "##############################################################\n",
    "\n",
    "## pip install scikit-image\n",
    "## pip install numpy\n",
    "\n",
    "###############################################################\n",
    "###############################################################\n",
    "\n",
    "#enable info logging.\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "def poly2mask(blobs, c, path_to_masks_folder, h, w, label, idx):\n",
    "    mask = np.zeros((h, w))\n",
    "    for l in blobs:\n",
    "        fill_row_coords, fill_col_coords = draw.polygon(l[1], l[0], l[2])\n",
    "        mask[fill_row_coords, fill_col_coords] = 1\n",
    "    io.imsave(path_to_masks_folder + \"/\" + str(c) + \"_\" + label + \"_\" + str(idx) + \".png\", mask)\n",
    "\n",
    "\n",
    "def convert_dataturks_to_masks(path_to_dataturks_annotation_json, path_to_original_images_folder, path_to_masks_folder):\n",
    "    # make sure everything is setup.\n",
    "    if (not os.path.isdir(path_to_original_images_folder)):\n",
    "        logging.exception(\n",
    "            \"Please specify a valid directory path to download images, \" + path_to_original_images_folder + \" doesn't exist\")\n",
    "        return\n",
    "    if (not os.path.isdir(path_to_masks_folder)):\n",
    "        logging.exception(\n",
    "            \"Please specify a valid directory path to write mask files, \" + path_to_masks_folder + \" doesn't exist\")\n",
    "        return\n",
    "    if (not os.path.exists(path_to_dataturks_annotation_json)):\n",
    "        logging.exception(\n",
    "            \"Please specify a valid path to dataturks JSON output file, \" + path_to_dataturks_annotation_json + \" doesn't exist\")\n",
    "        return\n",
    "    \n",
    "    print(path_to_dataturks_annotation_json) \n",
    "    f = open(path_to_dataturks_annotation_json)\n",
    "    train_data = f.readlines()\n",
    "    train = []\n",
    "    data = json.load(path_to_dataturks_annotation_json)\n",
    "    c = 0\n",
    "    for objects in train:\n",
    "        blobs = []\n",
    "        classes = {}\n",
    "        image = objects['content'][objects['content'].rfind('_') + 1:objects['content'].rfind('.')]\n",
    "        # download the images from given url\n",
    "        urllib.request.urlretrieve(objects['content'], path_to_original_images_folder + \"/image\" + str(c) + \".jpg\")\n",
    "        annotations = objects['annotation']\n",
    "\n",
    "        for annot in annotations:\n",
    "            blobs = []\n",
    "            label = annot['label']\n",
    "            if (label != ''):\n",
    "                if label not in classes:\n",
    "                    classes[label] = 0\n",
    "\n",
    "                points = annot['points']\n",
    "                h = annot['imageHeight']\n",
    "                w = annot['imageWidth']\n",
    "                x_coord = []\n",
    "                y_coord = []\n",
    "                l = []\n",
    "                for p in points:\n",
    "                    x_coord.append(p[0] * w)\n",
    "                    y_coord.append(p[1] * h)\n",
    "                shape = (h, w)\n",
    "                l.append(x_coord)\n",
    "                l.append(y_coord)\n",
    "                l.append(shape)\n",
    "                blobs.append(l)\n",
    "                poly2mask(blobs, c, path_to_masks_folder, annot['imageHeight'], annot['imageWidth'], label,\n",
    "                          classes[label])\n",
    "                classes[label] += 1\n",
    "        c += 1\n",
    "\n",
    "\n",
    "if (len(sys.argv) < 4):\n",
    "    print(\n",
    "    \"Please provide path to dataturks json file, path to store ground truth images and path to store mask images in this order.\")\n",
    "    exit(0)\n",
    "#convert_dataturks_to_masks(sys.argv[1], sys.argv[2], sys.argv[3])\n",
    "\n",
    "jsonF=\"C:\\\\workplace\\\\data\\\\3dircab\\\\train\\\\via_region_data.json\"\n",
    "originalPath=\"C:\\\\workplace\\\\data\\\\3dircab\\\\train\\\\\"\n",
    "maskPath=\"C:\\\\workplace\\\\data\\\\3dircab\\\\trainMask\\\\\"\n",
    "convert_dataturks_to_masks(jsonF, originalPath, maskPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.hooks import *\n",
    "import PIL.Image as PilImage\n",
    "\n",
    "def getClassValues(label_names):\n",
    "\n",
    "    containedValues = set([])\n",
    "\n",
    "    for i in range(len(label_names)):\n",
    "        tmp = open_mask(label_names[i])\n",
    "        tmp = tmp.data.numpy().flatten()\n",
    "        tmp = set(tmp)\n",
    "        containedValues = containedValues.union(tmp)\n",
    "    \n",
    "    return list(containedValues)\n",
    "\n",
    "def replaceMaskValuesFromZeroToN(mask,containedValues):\n",
    "\n",
    "    numberOfClasses = len(containedValues)\n",
    "    newMask = np.zeros(mask.shape)\n",
    "\n",
    "    for i in range(numberOfClasses):\n",
    "        newMask[mask == containedValues[i]] = i\n",
    "    \n",
    "    return newMask\n",
    "\n",
    "def convertMaskToPilAndSave(mask,saveTo):\n",
    "\n",
    "    imageSize = mask.squeeze().shape\n",
    "\n",
    "    im = PilImage.new('L',(imageSize[1],imageSize[0]))\n",
    "    im.putdata(mask.astype('uint8').ravel())\n",
    "    im.save(saveTo)\n",
    "\n",
    "def convertMasksToGrayscaleZeroToN(pathToLabels,saveToPath):\n",
    "\n",
    "    label_names = get_image_files(pathToLabels)\n",
    "    containedValues = getClassValues(label_names)\n",
    "\n",
    "    for currentFile in label_names:\n",
    "        currentMask = open_mask(currentFile).data.numpy()\n",
    "        convertedMask = replaceMaskValuesFromZeroToN(currentMask, containedValues)\n",
    "        convertMaskToPilAndSave(convertedMask, saveToPath/f'{currentFile.name}')\n",
    "    \n",
    "    print('Conversion finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
